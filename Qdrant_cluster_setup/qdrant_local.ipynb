{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PointStruct\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import uuid\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class RAGSystem:\n",
    "    def __init__(self, collection_name=\"documents\"):\n",
    "        # Initialize Qdrant client (local instance)\n",
    "        self.client = QdrantClient(\"localhost\", port=6333)\n",
    "        self.collection_name = collection_name\n",
    "        \n",
    "        # Initialize sentence transformer\n",
    "        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.vector_size = self.encoder.get_sentence_embedding_dimension()\n",
    "        \n",
    "        # Create collection if it doesn't exist\n",
    "        self.create_collection()\n",
    "\n",
    "    def create_collection(self):\n",
    "        \"\"\"Create a new collection in Qdrant.\"\"\"\n",
    "        self.client.recreate_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            vectors_config=VectorParams(size=self.vector_size, distance=Distance.COSINE)\n",
    "        )\n",
    "\n",
    "    def add_documents(self, documents):\n",
    "        \"\"\"\n",
    "        Add documents to the vector store.\n",
    "        \n",
    "        Args:\n",
    "            documents: List of dictionaries with 'text' and 'metadata' keys\n",
    "        \"\"\"\n",
    "        points = []\n",
    "        for doc in documents:\n",
    "            # Generate embeddings\n",
    "            embedding = self.encoder.encode(doc['text'])\n",
    "            \n",
    "            # Create point\n",
    "            point = PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=embedding.tolist(),\n",
    "                payload={\n",
    "                    'text': doc['text'],\n",
    "                    **doc.get('metadata', {})\n",
    "                }\n",
    "            )\n",
    "            points.append(point)\n",
    "\n",
    "        # Upload points in batch\n",
    "        self.client.upsert(\n",
    "            collection_name=self.collection_name,\n",
    "            points=points\n",
    "        )\n",
    "\n",
    "    def query(self, query_text, top_k=3):\n",
    "        \"\"\"\n",
    "        Query the vector store.\n",
    "        \n",
    "        Args:\n",
    "            query_text: String query\n",
    "            top_k: Number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of retrieved documents with similarity scores\n",
    "        \"\"\"\n",
    "        # Generate query embedding\n",
    "        query_vector = self.encoder.encode(query_text)\n",
    "        \n",
    "        # Search in Qdrant\n",
    "        results = self.client.search(\n",
    "            collection_name=self.collection_name,\n",
    "            query_vector=query_vector,\n",
    "            limit=top_k\n",
    "        )\n",
    "        \n",
    "        # Format results\n",
    "        retrieved_docs = []\n",
    "        for res in results:\n",
    "            retrieved_docs.append({\n",
    "                'text': res.payload['text'],\n",
    "                'metadata': {k: v for k, v in res.payload.items() if k != 'text'},\n",
    "                'similarity': res.score\n",
    "            })\n",
    "            \n",
    "        return retrieved_docs\n",
    "    \n",
    "    def save_collection(self, output_file):\n",
    "        \"\"\"Save collection to file without vectors\"\"\"\n",
    "        points = self.client.scroll(\n",
    "            collection_name=self.collection_name,\n",
    "            limit=10000\n",
    "        )[0]\n",
    "        \n",
    "        data = [{\n",
    "            'id': str(point.id),\n",
    "            'payload': point.payload\n",
    "        } for point in points]\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "    def restore_collection(self, input_file):\n",
    "        \"\"\"Restore collection from file with re-encoding\"\"\"\n",
    "        with open(input_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Recreate collection\n",
    "        self.create_collection()\n",
    "        \n",
    "        # Prepare points with new encodings\n",
    "        points = []\n",
    "        for point in data:\n",
    "            embedding = self.encoder.encode(point['payload']['text'])\n",
    "            points.append(PointStruct(\n",
    "                id=point['id'],\n",
    "                vector=embedding.tolist(),\n",
    "                payload=point['payload']\n",
    "            ))\n",
    "        \n",
    "        # Upload in batches of 100\n",
    "        batch_size = 100\n",
    "        for i in range(0, len(points), batch_size):\n",
    "            batch = points[i:i + batch_size]\n",
    "            self.client.upsert(\n",
    "                collection_name=self.collection_name,\n",
    "                points=batch\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAG system\n",
    "rag = RAGSystem()\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    {\n",
    "        'text': 'The quick brown fox jumps over the lazy dog.',\n",
    "        'metadata': {'source': 'sample1', 'date': '2024-01-25'}\n",
    "    },\n",
    "    {\n",
    "        'text': 'Python is a versatile programming language.',\n",
    "        'metadata': {'source': 'sample2', 'date': '2024-01-25'}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Add documents\n",
    "rag.add_documents(documents)\n",
    "\n",
    "# Query\n",
    "results = rag.query(\"Tell me about Python\")\n",
    "for result in results:\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Similarity: {result['similarity']}\")\n",
    "    print(f\"Metadata: {result['metadata']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "collections = client.get_collections()\n",
    "\n",
    "for collection in collections.collections:\n",
    "    print(f\"Collection name: {collection.name}\")\n",
    "    print(f\"Points count: {client.get_collection(collection.name).points_count}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "def inspect_collection(collection_name, limit=5):\n",
    "    client = QdrantClient(\"localhost\", port=6333)\n",
    "    \n",
    "    points = client.scroll(\n",
    "        collection_name=collection_name,\n",
    "        limit=limit\n",
    "    )[0]\n",
    "    \n",
    "    print(f\"\\nCollection: {collection_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    for point in points:\n",
    "        print(f\"ID: {point.id}\")\n",
    "        print(f\"Payload: {point.payload}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Inspect each collection\n",
    "collections = [\"data\"]\n",
    "for collection in collections:\n",
    "    inspect_collection(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "collection_info = client.get_collection(\"data\")\n",
    "print(f\"Total points in collection 'data': {collection_info.points_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sAVE COLLECTION AND RESTORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, Distance\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "def save_collection_light(collection_name, output_file):\n",
    "    client = QdrantClient(\"localhost\", port=6333)\n",
    "    points = client.scroll(collection_name=collection_name, limit=100)[0]\n",
    "    \n",
    "    data = [{\n",
    "        'id': str(point.id),\n",
    "        'payload': point.payload\n",
    "    } for point in points]\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def restore_collection_with_encoding(input_file, collection_name, model_name='all-MiniLM-L6-v2'):\n",
    "    client = QdrantClient(\"localhost\", port=6333)\n",
    "    encoder = SentenceTransformer(model_name)\n",
    "    \n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Create collection\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=encoder.get_sentence_embedding_dimension(), distance=Distance.COSINE)\n",
    "    )\n",
    "    \n",
    "    # Encode and restore points\n",
    "    points = [{\n",
    "        'id': point['id'],\n",
    "        'vector': encoder.encode(point['payload']['text']).tolist(),\n",
    "        'payload': point['payload']\n",
    "    } for point in data]\n",
    "    \n",
    "    client.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "# Usage\n",
    "save_collection_light(\"documents\", \"documents_light.json\")\n",
    "restore_collection_with_encoding(\"documents_light.json\", \"documents_new\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
